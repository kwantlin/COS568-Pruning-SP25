Namespace(dataset='mnist', model='fc', model_class='default', dense_classifier=False, pretrained=False, optimizer='adam', train_batch_size=256, test_batch_size=256, pre_epochs=0, post_epochs=10, lr=0.001, lr_drops=[], lr_drop_rate=0.1, weight_decay=0.0, pruner='snip', compression=1.0, quantization=False, prune_epochs=1, compression_schedule='exponential', mask_scope='global', prune_dataset_ratio=10, prune_batch_size=256, prune_bias=False, prune_batchnorm=False, prune_residual=False, prune_train_mode=False, reinitialize=False, shuffle=False, invert=False, pruner_list=[], prune_epoch_list=[], compression_list=[], level_list=[], experiment='singleshot', expid='mnist-fc-default-snip-preEpochs0-postEpochs10-compression1', result_dir='Results/data', gpu=0, workers=4, no_cuda=False, seed=1, verbose=False)
Loading mnist dataset.
Creating default-fc model.
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snip for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.03it/s]100%|██████████| 1/1 [00:00<00:00,  4.02it/s]
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s]Time:  2.2355876789661124
 10%|█         | 1/10 [00:15<02:19, 15.49s/it]Time:  2.5260334590566345
 20%|██        | 2/10 [00:31<02:06, 15.81s/it]Time:  2.38245991198346
 30%|███       | 3/10 [00:46<01:46, 15.28s/it]Time:  2.2962091109948233
 40%|████      | 4/10 [01:00<01:30, 15.09s/it]Time:  2.1788092000060715
 50%|█████     | 5/10 [01:14<01:12, 14.58s/it]Time:  2.2228575629997067
 60%|██████    | 6/10 [01:28<00:57, 14.50s/it]Time:  2.28918917599367
 70%|███████   | 7/10 [01:44<00:44, 14.73s/it]Time:  1.8371397519949824
 80%|████████  | 8/10 [01:57<00:28, 14.19s/it]Time:  2.7827311800210737
 90%|█████████ | 9/10 [02:11<00:14, 14.36s/it]Time:  2.2192642480367795
100%|██████████| 10/10 [02:28<00:00, 15.05s/it]100%|██████████| 10/10 [02:28<00:00, 14.86s/it]
Post-training time: 150.81 seconds
GPU memory allocated: 20.41 MB, peak: 22.71 MB
Train results:
                train_loss  test_loss  top1_accuracy  top5_accuracy  test_time
Init.      0          NaN   2.306856          10.32          47.39   2.154001
Pre-Prune  0          NaN   2.306856          10.32          47.39   2.154001
Post-Prune 0          NaN   2.306854          10.32          49.80   2.201307
Final      10    0.129154   0.144069          95.56          99.80   2.219264
Prune results:
    module   param  sparsity   size       shape  flops  score mean  score variance  score sum  score abs mean  score abs variance  score abs sum  prunable
0       1  weight  0.054056  78400  (100, 784)  78400    0.000005    5.989313e-11   0.404448        0.000005        5.989313e-11       0.404448      True
1       1    bias  1.000000    100      (100,)    100    0.000000    0.000000e+00   0.000000        0.000000        0.000000e+00       0.000000     False
2       3  weight  0.218900  10000  (100, 100)  10000    0.000013    4.284687e-10   0.125934        0.000013        4.284687e-10       0.125934      True
3       3    bias  1.000000    100      (100,)    100    0.000000    0.000000e+00   0.000000        0.000000        0.000000e+00       0.000000     False
4       5  weight  0.181800  10000  (100, 100)  10000    0.000011    4.830764e-10   0.111812        0.000011        4.830764e-10       0.111812      True
5       5    bias  1.000000    100      (100,)    100    0.000000    0.000000e+00   0.000000        0.000000        0.000000e+00       0.000000     False
6       7  weight  0.151100  10000  (100, 100)  10000    0.000010    6.846698e-10   0.103630        0.000010        6.846698e-10       0.103630      True
7       7    bias  1.000000    100      (100,)    100    0.000000    0.000000e+00   0.000000        0.000000        0.000000e+00       0.000000     False
8       9  weight  0.176600  10000  (100, 100)  10000    0.000016    2.011727e-09   0.158670        0.000016        2.011727e-09       0.158670      True
9       9    bias  1.000000    100      (100,)    100    0.000000    0.000000e+00   0.000000        0.000000        0.000000e+00       0.000000     False
10     11  weight  0.418000   1000   (10, 100)   1000    0.000096    5.414623e-08   0.095505        0.000096        5.414623e-08       0.095505      True
11     11    bias  1.000000     10       (10,)     10    0.000000    0.000000e+00   0.000000        0.000000        0.000000e+00       0.000000     False
Parameter Sparsity: 12449/119910 (0.1038)
FLOP Sparsity: 12449/119910 (0.1038)
Saving results.
